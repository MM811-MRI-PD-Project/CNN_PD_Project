{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "//anaconda/lib/python3.5/site-packages/dicom/__init__.py:53: UserWarning: \n",
      "This code is using an older version of pydicom, which is no longer \n",
      "maintained as of Jan 2017.  You can access the new pydicom features and API \n",
      "by installing `pydicom` from PyPI.\n",
      "See 'Transitioning to pydicom 1.x' section at pydicom.readthedocs.org \n",
      "for more information.\n",
      "\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "# A simple CNN to predict certain characteristics of the human subject from MRI images.\n",
    "# 3d convolution is used in each layer.\n",
    "# Reference: https://www.tensorflow.org/get_started/mnist/pros, http://blog.naver.com/kjpark79/220783765651\n",
    "# Adjust needed for your dataset e.g., max pooling, convolution parameters, training_step, batch size, etc\n",
    "\n",
    "width = 128\n",
    "height = 128\n",
    "depth = 121\n",
    "nLabel = 2\n",
    "\n",
    "# Start TensorFlow InteractiveSession\n",
    "from input_3Dimage import get_data_MRI\n",
    "import tensorflow as tf\n",
    "sess = tf.InteractiveSession()\n",
    "\n",
    "# Placeholders (MNIST image:28x28pixels=784, label=10)\n",
    "x = tf.placeholder(tf.float32, shape=[None, width*height*depth]) # [None, 28*28]\n",
    "y_ = tf.placeholder(tf.float32, shape=[None, nLabel])  # [None, 10]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Weight Initialization\n",
    "# Create lots of weights and biases & Initialize with a small positive number as we will use ReLU\n",
    "def weight_variable(shape):\n",
    "  initial = tf.truncated_normal(shape, stddev=0.1)\n",
    "  return tf.Variable(initial)\n",
    "\n",
    "def bias_variable(shape):\n",
    "  initial = tf.constant(0.1, shape=shape)\n",
    "  return tf.Variable(initial)\n",
    "\n",
    "## Convolution and Pooling\n",
    "# Convolution here: stride=1, zero-padded -> output size = input size\n",
    "def conv3d(x, W):\n",
    "  return tf.nn.conv3d(x, W, strides=[1, 1, 1, 1, 1], padding='SAME') # conv2d, [1, 1, 1, 1]\n",
    "\n",
    "# Pooling: max pooling over 2x2 blocks\n",
    "def max_pool_2x2(x):  # tf.nn.max_pool. ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1]\n",
    "  return tf.nn.max_pool3d(x, ksize=[1, 4, 4, 4, 1], strides=[1, 4, 4, 4, 1], padding='SAME')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bound method Tensor.get_shape of <tf.Tensor 'Reshape:0' shape=(?, 128, 128, 121, 1) dtype=float32>>\n",
      "<bound method Tensor.get_shape of <tf.Tensor 'Relu:0' shape=(?, 128, 128, 121, 32) dtype=float32>>\n",
      "<bound method Tensor.get_shape of <tf.Tensor 'MaxPool3D:0' shape=(?, 32, 32, 31, 32) dtype=float32>>\n",
      "<bound method Tensor.get_shape of <tf.Tensor 'Relu_1:0' shape=(?, 32, 32, 31, 64) dtype=float32>>\n",
      "<bound method Tensor.get_shape of <tf.Tensor 'MaxPool3D_1:0' shape=(?, 8, 8, 8, 64) dtype=float32>>\n"
     ]
    }
   ],
   "source": [
    "## First Convolutional Layer\n",
    "# Conv then Max-pooling. 1st layer will have 32 features for each 5x5 patch. (1 feature -> 32 features)\n",
    "W_conv1 = weight_variable([5, 5, 5, 1, 32])  # shape of weight tensor = [5,5,1,32]\n",
    "b_conv1 = bias_variable([32])  # bias vector for each output channel. = [32]\n",
    "\n",
    "# Reshape 'x' to a 4D tensor (2nd dim=image width, 3rd dim=image height, 4th dim=nColorChannel)\n",
    "x_image = tf.reshape(x, [-1,width,height,depth,1]) # [-1,28,28,1]\n",
    "print(x_image.get_shape) # (?, 256, 256, 40, 1)  # -> output image: 28x28 x1\n",
    "\n",
    "# x_image * weight tensor + bias -> apply ReLU -> apply max-pool\n",
    "h_conv1 = tf.nn.relu(conv3d(x_image, W_conv1) + b_conv1)  # conv2d, ReLU(x_image * weight + bias)\n",
    "print(h_conv1.get_shape) # (?, 256, 256, 40, 32)  # -> output image: 28x28 x32\n",
    "h_pool1 = max_pool_2x2(h_conv1)  # apply max-pool \n",
    "print(h_pool1.get_shape) # (?, 128, 128, 20, 32)  # -> output image: 14x14 x32\n",
    "\n",
    "\n",
    "## Second Convolutional Layer\n",
    "# Conv then Max-pooling. 2nd layer will have 64 features for each 5x5 patch. (32 features -> 64 features)\n",
    "W_conv2 = weight_variable([5, 5, 5, 32, 64]) # [5, 5, 32, 64]\n",
    "b_conv2 = bias_variable([64]) # [64]\n",
    "\n",
    "h_conv2 = tf.nn.relu(conv3d(h_pool1, W_conv2) + b_conv2)  # conv2d, .ReLU(x_image * weight + bias)\n",
    "print(h_conv2.get_shape) # (?, 128, 128, 20, 64)  # -> output image: 14x14 x64\n",
    "h_pool2 = max_pool_2x2(h_conv2)  # apply max-pool \n",
    "print(h_pool2.get_shape) # (?, 64, 64, 10, 64)    # -> output image: 7x7 x64\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bound method Tensor.get_shape of <tf.Tensor 'Reshape_1:0' shape=(?, 32768) dtype=float32>>\n",
      "<bound method Tensor.get_shape of <tf.Tensor 'Relu_2:0' shape=(?, 1024) dtype=float32>>\n",
      "<bound method Tensor.get_shape of <tf.Tensor 'dropout/mul:0' shape=(?, 1024) dtype=float32>>\n",
      "<bound method Tensor.get_shape of <tf.Tensor 'add_3:0' shape=(?, 2) dtype=float32>>\n"
     ]
    }
   ],
   "source": [
    "## Densely Connected Layer (or fully-connected layer)\n",
    "# fully-connected layer with 1024 neurons to process on the entire image\n",
    "W_fc1 = weight_variable([8*8*8*64, 1024])  # [7*7*64, 1024]\n",
    "b_fc1 = bias_variable([1024]) # [1024]]\n",
    "\n",
    "h_pool2_flat = tf.reshape(h_pool2, [-1, 8*8*8*64])  # -> output image: [-1, 7*7*64] = 3136\n",
    "print(h_pool2_flat.get_shape)  # (?, 2621440)\n",
    "h_fc1 = tf.nn.relu(tf.matmul(h_pool2_flat, W_fc1) + b_fc1)  # ReLU(h_pool2_flat x weight + bias)\n",
    "print(h_fc1.get_shape) # (?, 1024)  # -> output: 1024\n",
    "\n",
    "## Dropout (to reduce overfitting; useful when training very large neural network)\n",
    "# We will turn on dropout during training & turn off during testing\n",
    "keep_prob = tf.placeholder(tf.float32)\n",
    "h_fc1_drop = tf.nn.dropout(h_fc1, keep_prob)\n",
    "print(h_fc1_drop.get_shape)  # -> output: 1024\n",
    "\n",
    "## Readout Layer\n",
    "W_fc2 = weight_variable([1024, nLabel]) # [1024, 10]\n",
    "b_fc2 = bias_variable([nLabel]) # [10]\n",
    "\n",
    "y_conv = tf.matmul(h_fc1_drop, W_fc2) + b_fc2\n",
    "print(y_conv.get_shape)  # -> output: 10\n",
    "\n",
    "## Train and Evaluate the Model\n",
    "# set up for optimization (optimizer:ADAM)\n",
    "cross_entropy = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(labels=y_, logits=y_conv))\n",
    "train_step = tf.train.AdamOptimizer(1e-3).minimize(cross_entropy)  # 1e-4\n",
    "correct_prediction = tf.equal(tf.argmax(y_conv,1), tf.argmax(y_,1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "# Include keep_prob in feed_dict to control dropout rate.\n",
    "for i in range(100):\n",
    "    batch = get_data_MRI(sess,'train',20)\n",
    "    # Logging every 100th iteration in the training process.\n",
    "    if i%5 == 0:\n",
    "        train_accuracy = accuracy.eval(feed_dict={x:batch[0], y_: batch[1], keep_prob: 1.0})\n",
    "        print(\"step %d, training accuracy %g\"%(i, train_accuracy))\n",
    "    train_step.run(feed_dict={x: batch[0], y_: batch[1], keep_prob: 0.5})\n",
    "\n",
    "# Evaulate our accuracy on the test data\n",
    "testset = get_data_MRI(sess,'test',30)\n",
    "print(\"test accuracy %g\"%accuracy.eval(feed_dict={x: testset[0], y_: teseset[1], keep_prob: 1.0}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:anaconda]",
   "language": "python",
   "name": "conda-env-anaconda-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
